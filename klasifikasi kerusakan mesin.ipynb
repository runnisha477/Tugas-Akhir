{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import here as get_project_root\n",
    "import os\n",
    "os.chdir(get_project_root()) # hack for notebook development\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import data_acquisition.data_acquisition_config as config\n",
    "from data_acquisition.custom_types import Dataset\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def _dataReader(path_names:list) -> list:\n",
    "    '''\n",
    "    Reads in raw data from .csv files and returns a list\n",
    "    \n",
    "    params:\n",
    "    ---\n",
    "    path_names (list): list of all the data files to read in\n",
    "    \n",
    "    returns:\n",
    "    ---\n",
    "    sequences (list): raw dataset from data directory\n",
    "    '''\n",
    "    \n",
    "    sequences = list()\n",
    "    \n",
    "    for name in path_names:\n",
    "        data = pd.read_csv(name, header=None)\n",
    "        sequences.append(data.values)\n",
    "          \n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_data() -> Dataset:\n",
    "    '''\n",
    "    runs the `_dataReader` method and stores the raw data into a Dataset named tuple. \n",
    "    \n",
    "    returns:\n",
    "    ---\n",
    "    dataset (Dataset): named tuple of (data_n)\n",
    "    '''\n",
    "    \n",
    "    logging.info(f\"Loading raw data.\")\n",
    "    \n",
    "    data_normal = np.stack(_dataReader(config.NORMAL_FILE_NAMES))\n",
    "    data_horizontal = np.stack(_dataReader(config.HORI_MIS_FILE_NAMES))\n",
    "    data_vertical = np.stack(_dataReader(config.VERT_MIS_FILE_NAMES))\n",
    "    data_imbalance = np.stack(_dataReader(config.IMBALANCE_FILE_NAMES))\n",
    "    data_overhang = np.stack(_dataReader(config.OVERHANG_FILE_NAMES))\n",
    "    data_underhang = np.stack(_dataReader(config.UNDERHANG_FILE_NAMES))\n",
    "    \n",
    "    logging.info(f\"Load complete.\")\n",
    "    \n",
    "    dataset = Dataset(data_normal, data_horizontal, data_vertical, data_imbalance, data_overhang, data_underhang)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find module 'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\.libs\\libbanded5x.EHDKC2XVYTQQ5MALRS6XN2CUSS6SRL6P.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8696/2116322680.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrfft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m from .utils._tags import (\n\u001b[0;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;31m# Allow distributors to run custom init code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pep440\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\_distributor_init.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*dll'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mWinDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mowd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\.libs\\libbanded5x.EHDKC2XVYTQQ5MALRS6XN2CUSS6SRL6P.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Any utility function that is required for data processing goes here\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.fft import rfft\n",
    "\n",
    "\n",
    "def _dataScaler(data:list) -> list:\n",
    "    '''\n",
    "    Reads in data and returns a scaled list.\n",
    "    \n",
    "    params:\n",
    "    ---\n",
    "    data (list): data to down sample\n",
    "    \n",
    "    returns:\n",
    "    ---\n",
    "    final_sequence (list): resampled data\n",
    "    '''   \n",
    "    data_temp = np.reshape(data, (-1, data.shape[2]))    \n",
    "    norm = MinMaxScaler().fit(data_temp)   \n",
    "    data_norm = norm.transform(data_temp)    \n",
    "    data_final = np.reshape(data_norm, (-1, data.shape[1], data.shape[2]))\n",
    "    \n",
    "    return data_final\n",
    "\n",
    "\n",
    "def _downSampler(data:list, start_index:int, sample_rate:int) -> list:\n",
    "    '''\n",
    "    Reads in raw data from .csv files and returns a resampled list\n",
    "    \n",
    "    params:\n",
    "    ---\n",
    "    data (list): data to down sample\n",
    "    start_index (int): starting index\n",
    "    sample_rate (int): sampling rate\n",
    "    \n",
    "    returns:\n",
    "    ---\n",
    "    final_sequence (list): resampled data\n",
    "    '''    \n",
    "    final_sequence = list()\n",
    "    for dataset in data:\n",
    "        data_resampled = []\n",
    "        start = start_index\n",
    "        stop = sample_rate\n",
    "        for i in range(int(len(dataset)/sample_rate)):\n",
    "            data_resampled.append(dataset[start:stop, :].mean(axis=0))\n",
    "            start += sample_rate\n",
    "            stop += sample_rate\n",
    "        final_sequence.append(np.stack(data_resampled))    \n",
    "        \n",
    "    return np.stack(final_sequence)\n",
    "\n",
    "\n",
    "def _FFT(data:list) -> list:\n",
    "    '''\n",
    "    Reads in resampled data and peforms a Fast Fourier Transform with DC offset removal\n",
    "    \n",
    "    params:\n",
    "    ---\n",
    "    data (pd.DataFrame): data to perform Fast Fourier Transform\n",
    "    \n",
    "    returns:\n",
    "    ---\n",
    "    data_fft (list): FFT data\n",
    "    '''\n",
    "    data_fft = list()\n",
    "    for dataset in data:\n",
    "        data_fft.append(np.stack(np.abs(rfft(dataset, axis=0))[1:,:]))\n",
    "    \n",
    "    return np.stack(data_fft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import collections\n",
    "import os\n",
    "import re\n",
    "\n",
    "path_parent = os.path.dirname(os.getcwd())\n",
    "os.chdir(path_parent)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# -\n",
    "\n",
    "from data_acquisition.main import get_data\n",
    "from data_processing.utils import _dataScaler, _downSampler, _FFT\n",
    "import data_processing.data_processing_config as config\n",
    "\n",
    "Dataset = collections.namedtuple('Dataset', 'X_train X_test y_train y_test')\n",
    "\n",
    "\n",
    "def get_train_test_data(raw_data:Dataset) -> Dataset:\n",
    "    '''\n",
    "    runs the 'get_data()' and '_downSampler' methods to generate training and testing data sets\n",
    "    \n",
    "    params:\n",
    "    ---\n",
    "    dataset (Dataset): raw data set from data_acquisition module\n",
    "    \n",
    "    returns:\n",
    "    ---\n",
    "    train_test_data (Dataset): named tuple of (X_train, y_train, X_test, y_test)\n",
    "    '''   \n",
    "    logging.info(f\"Data is being resampled at a sample rate of: {config.RESAMPLE_RATE}\")    \n",
    "    data_n = _downSampler(raw_data.normal, 0, config.RESAMPLE_RATE)\n",
    "    data_horizontal = _downSampler(raw_data.horizontal, 0, config.RESAMPLE_RATE)\n",
    "    data_imbalance = _downSampler(raw_data.imbalance, 0, config.RESAMPLE_RATE)\n",
    " \n",
    "    logging.info(f\"Scaling the data.\")\n",
    "    data_n = _dataScaler(data_n)\n",
    "    data_horizontal = _dataScaler(data_horizontal)\n",
    "    data_imbalance = _dataScaler(data_imbalance)\n",
    "       \n",
    "    logging.info(f\"Performing FFT.\")\n",
    "    data_n = _FFT(data_n)\n",
    "    data_horizontal = _FFT(data_horizontal)\n",
    "    data_imbalance = _FFT(data_imbalance)\n",
    "    \n",
    "    y_1 = np.zeros(int(len(data_n)),dtype=int)\n",
    "    y_2 = np.full(int(len(data_horizontal)),1)\n",
    "    y_3 = np.full(int(len(data_imbalance)),2)\n",
    "    y = np.concatenate((y_1, y_2, y_3))\n",
    "    \n",
    "    X = np.concatenate((data_n, data_horizontal, data_imbalance))\n",
    "    \n",
    "    logging.info(f\"Spliting data to a test size of: {config.DATA_TEST_SIZE}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=config.DATA_TEST_SIZE, random_state=42)\n",
    "       \n",
    "    train_test_data = Dataset(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    logging.info(f\"Complete. Happy modelling :).\")\n",
    "    \n",
    "    return train_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Any utility function that is required for data exploratory analysis goes here\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import rfftfreq\n",
    "import data_processing.data_processing_config as config\n",
    "\n",
    "\n",
    "def time_plot(yf:np.ndarray, start:int, stop:int):\n",
    "    '''\n",
    "    Plots a time series\n",
    "    \n",
    "    params:\n",
    "    ---\n",
    "    yf (np.ndarray): input data to plot\n",
    "    sample_rate (int): sampling rate (Hz)\n",
    "    duration (int): signal duration in seconds\n",
    "    '''   \n",
    "    time = np.linspace(0, config.DURATION, len(yf), endpoint=False)\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=1, figsize=(11, 9))\n",
    "    plt.rcParams['font.size'] = '14'\n",
    "    \n",
    "    for label in (axs.get_xticklabels() + axs.get_yticklabels()):\n",
    "        label.set_fontsize(14)\n",
    "    \n",
    "    plt.plot(time[start:stop], yf[start:stop])\n",
    "    axs.set_title('Time-series signal')\n",
    "    axs.set_ylabel('Voltage (V)', fontsize=14)\n",
    "    axs.set_xlabel('Time (s)', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fft_plot(yf:np.ndarray):\n",
    "    '''\n",
    "    Plots the FFT\n",
    "    \n",
    "    params:\n",
    "    ---\n",
    "    yf (np.ndarray): input data to plot\n",
    "    sample_rate (int): sampling rate (Hz)\n",
    "    duration (int): signal duration in seconds\n",
    "    '''   \n",
    "    N = int((config.SAMPLE_RATE / config.RESAMPLE_RATE) * config.DURATION)\n",
    "    xf = rfftfreq(N-1, 1 / int(config.SAMPLE_RATE / config.RESAMPLE_RATE))\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=1, figsize=(11, 9))\n",
    "    plt.rcParams['font.size'] = '14'\n",
    "    \n",
    "    for label in (axs.get_xticklabels() + axs.get_yticklabels()):\n",
    "        label.set_fontsize(14)\n",
    "    \n",
    "    plt.plot(xf, yf)\n",
    "    axs.set_title('Frequency spectra')\n",
    "    axs.set_ylabel('Signal strength', fontsize=14)\n",
    "    axs.set_xlabel('Frequency (Hz)', fontsize=14)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import here as get_project_root\n",
    "import os\n",
    "os.chdir(get_project_root()) # hack for notebook development\n",
    "\n",
    "# +\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import collections\n",
    "import os\n",
    "import re\n",
    "from data_acquisition.main import get_data\n",
    "from data_processing.main import get_train_test_data\n",
    "from model_training import model_training_config as config\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "path_parent = os.path.dirname(os.getcwd())\n",
    "os.chdir(path_parent)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# -\n",
    "\n",
    "# ## Model Development\n",
    "\n",
    "# Load the data\n",
    "dataset = get_data()\n",
    "\n",
    "# Process the data and train/test split\n",
    "train_test_data = get_train_test_data(dataset)\n",
    "\n",
    "# +\n",
    "# Prepare the data\n",
    "X_train = np.array(train_test_data.X_train)\n",
    "X_test = np.array(train_test_data.X_test)\n",
    "\n",
    "y_train = np.array(train_test_data.y_train)\n",
    "y_test = np.array(train_test_data.y_test)\n",
    "# -\n",
    "# Generating the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(config.LSTM_UNITS, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(config.OUTPUT_SIZE, activation=config.ACTIVATION))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Training the model\n",
    "chk = ModelCheckpoint('best_model.pkl', monitor=config.MONITOR, save_best_only=True, mode='auto', verbose=1)\n",
    "model.compile(loss=config.LOSS_FUNCTION, optimizer=config.OPTIMIZER, metrics=['accuracy'])\n",
    "hist = model.fit(X_train, y_train, epochs=config.EPOCHS, batch_size=int(X_train.shape[0]), callbacks=[chk], validation_split=config.VAL_SPLOT)\n",
    "\n",
    "# ## Model Validation\n",
    "\n",
    "# +\n",
    "# Plotting training and validation accuracy per epoch\n",
    "fig, axs = plt.subplots(nrows=1, figsize=(11, 9))\n",
    "plt.rcParams['font.size'] = '14'\n",
    "    \n",
    "for label in (axs.get_xticklabels() + axs.get_yticklabels()):\n",
    "    label.set_fontsize(14)    \n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "\n",
    "axs.set_title('Model Accuracy')\n",
    "axs.set_ylabel('Accuracy', fontsize=14)\n",
    "axs.set_xlabel('Epoch', fontsize=14)\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# +\n",
    "# Loading the model and checking accuracy on the test data\n",
    "model = load_model('best_model.pkl')\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = model.predict_classes(X_test)\n",
    "accuracy_score(y_test, test_preds)\n",
    "# -\n",
    "\n",
    "# Comparing the actual values versus the predicted values\n",
    "data_dict = {0:'normal', 1:'horizontal misalignment', 2:'imbalance'}\n",
    "results = pd.DataFrame([y_test, test_preds]).T\n",
    "results.columns = ['Actual', 'Prediction']\n",
    "results.applymap(lambda x: data_dict[x])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
